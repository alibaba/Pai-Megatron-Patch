- algorithm.adv_estimator=grpo
- data.train_files=['/mnt/data/datasets/gsm8k/train.parquet']
- data.val_files=['/mnt/data/datasets/gsm8k/test.parquet']
- data.train_batch_size=16
- data.max_prompt_length=1024
- data.max_response_length=2048
- data.filter_overlong_prompts=False
- data.truncation=error
- actor_rollout_ref.model.path=/mnt/data/ckpts/huggingface/Qwen3-8B
- actor_rollout_ref.actor.optim.lr=2e-6
- actor_rollout_ref.actor.ppo_mini_batch_size=8
- actor_rollout_ref.actor.use_dynamic_bsz=False
- +actor_rollout_ref.model.use_remove_padding=False
- actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=8
- actor_rollout_ref.actor.megatron.pipeline_model_parallel_size=1
- actor_rollout_ref.actor.megatron.tensor_model_parallel_size=2
- actor_rollout_ref.actor.megatron.expert_model_parallel_size=1
- actor_rollout_ref.actor.megatron.use_dist_checkpointing=True
- actor_rollout_ref.actor.megatron.dist_checkpointing_path=/mnt/data/ckpts/mcore/Qwen3-8B-to-mcore-verl
- actor_rollout_ref.actor.use_kl_loss=True
- actor_rollout_ref.actor.kl_loss_coef=0.0
- actor_rollout_ref.actor.kl_loss_type=low_var_kl
- actor_rollout_ref.actor.entropy_coeff=0
- actor_rollout_ref.model.enable_gradient_checkpointing=True
- actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=8
- actor_rollout_ref.rollout.tensor_model_parallel_size=2
- actor_rollout_ref.rollout.name=vllm
- actor_rollout_ref.rollout.gpu_memory_utilization=0.6
- actor_rollout_ref.rollout.n=32
- actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=8
- actor_rollout_ref.ref.megatron.pipeline_model_parallel_size=1
- actor_rollout_ref.ref.megatron.tensor_model_parallel_size=2
- actor_rollout_ref.ref.megatron.expert_model_parallel_size=1
- actor_rollout_ref.ref.megatron.use_dist_checkpointing=True
- actor_rollout_ref.ref.megatron.dist_checkpointing_path=/mnt/data/ckpts/mcore/Qwen3-8B-to-mcore-verl
- algorithm.use_kl_in_reward=False
- trainer.critic_warmup=0
- trainer.logger=[console]
- trainer.project_name=verl_grpo_example_gsm8k_math
- trainer.experiment_name=qwen3_30b_moe_megatron
- trainer.n_gpus_per_node=8
- trainer.nnodes=1
- trainer.save_freq=-1
- trainer.test_freq=1
- trainer.total_epochs=50
